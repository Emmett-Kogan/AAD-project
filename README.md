# AAD-project
All I know is that for now I should implement Bellman-Ford-Moore

## Contributor(s)
1. Emmett Kogan

## Build Instructions
The Makefile has 3 rules, `debug` which compiles both the bfm object file and aqueduct with `DEBUG` defined. This may have leftover unwanted prints/additional information about how the program is being run outputted on `stdout` and `stderr`. Furthermore, `DEBUG` changes the way the program looks for `grid.txt`. Instead of assuming it is in `./grid.txt` it takes a command line arguement that is a relative path to the desired input file (this was just done for easier testing). 

There is also the `big` rule which does all of what `debug` does, but also changes the order in which rows and columns are inputted into the program so that it could work with the large randomly genrated testcases someone posted on discord.

As specified, the `default` rule builds a program that fits the specifications as far as input file, output file and I *think* all debug statements are inside ifdefs (this is also the first rule so just running `make` runs this one).

## Report
My solution to this project obviosly involves parsing the input file to get all relevant node information, storing that in a 2d array of integers, then building a graph (in the form of an edge-list) from that array using the provided cost function. Note that the number of stations is rows*cols, and since each station can have up to 4 outgoing edges this is just a grid graph, which has `2*n*m-n-m` edges. For a directionless grid graph there's just twice as many edges. So in the worst case, I'm using like 237.6KB of memory to represent this. There's probably a better way but call me Google Chrome :). Using this edge list, I perform Bellman-Ford for the src node, and each node in B. I based my implementation off of the one on GeeksForGeeks, though I originally planned to do something more complex if I needed to make this faster, but, I didn't run into a time problem with this, and either way I multithreaded it and this is not the slowdown. The way this implemntation works, is that it initializes a distance array to represent the path length to each node (1D). Using this, it relaxes the edges |V|-1 times to find the shortest paths via relaxing edges. Then performs a sanity check to prevent not finding negative weight cycles (but I'm relativley confident that this is impossible in this problem). It returns a pointer to a dynamically allocated array of paths that is indexed by node number, where node number is `row*cols + col`, and is simply used later to identify each node in the graph.

As I stated earlier, I figured this would be slow, and prior to running the large test case I multithreaded it such that all 1+|B| calls would happen at the same time anywayus. From this I essentially obtained a new graph, where the only nodes were src and those from B, and the edges would be the path lengths between them. I could've done some better TSP traversal, but, at the end of the day the maximum permutations of this is 8!, so I just brute forced it at first to see if that would meet the timing constraints, and it did. As far as time-complexity, Parsing the input file is essentially O(n), where n is the number of nodes, but it may be more conveinent to call this O(rows*cols). Generating the graph involves O(E) insertions into an array, where `E = 2(2*rows*cols-rows*cols)`, and reducing this results in O(rows\*cols) (after dropping a constant 2). The following operation is 1+|B| calls to Bellman Ford, which this implementation runs in O(VE), so in terms of rows and cols O((rows\*cols)<sup>2</sup>). This happens |B| times, so technically the time complexity of all of this is O(|B|\*(rows\*cols)<sup>2</sup>), but B <= 8 AND this is being run in parallel, so I'm going to drop it as a constant. The final operation is brute forcing the permutations. This is again, technically O(|B|!), but really this is only checking 40Kish permutations, which on any CPU in with a clock in the GHz range, is basically constant time. So, the time complexity of my solution is O(|B|(rows\*cols)<sup>2</sup> + rows\*cols + |B|!) -> O(|B|(rows\*cols)<sup>2</sup>), but after taking into account multithreading and how the brute forcing of permutations at the end won't scale relative to the size of the graph, when it actually runs is probably closer to O((rows\*cols)<sup>2</sup>)